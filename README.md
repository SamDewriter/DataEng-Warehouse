# DataEngineering - Warehouse

## Overview
An AI startup deploys sensors to businesses, collects data from all activities in a business - from people’s interaction to the smart appliances installed in the company to reading environmental and other relevant information. Our startup is responsible to install all the required sensors, receive a stream of data from all sensors, and analyze the data to provide key insights to the business. This project focuses on creating the required scalable data warehouse tech-stack that can receive a stream of data, collect the data, and store it in a warehouse. The data stored is then analysed to provide key insights to the business. The tech-stack used to create the data warehouse are MySQL, dbt, Spark, and Airflow.  

## Data Source
The data used in this project is obtained from https://anson.ucdavis.edu/~clarkf/. It is a sensor data.

## Objectives
The fundamental goal achieved in this project 
A “data warehouse (MySQL) was built
An orchestration service (Airflow) was used to automate the pprocess
An ELT tool (dbt) was used to transform the data
A reporting environment (redash) was used to create a dashboard

## Requirements
The following tools are very necessary to carry out this project:
- Apache Airflow
- dbt
- MySQL/PostgreSL
- Redash
pip install requirements.txt
